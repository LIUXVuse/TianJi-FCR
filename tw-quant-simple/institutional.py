# -*- coding: utf-8 -*-
"""
ä¸‰å¤§æ³•äººè²·è³£è¶…è³‡æ–™æŠ“å–æ¨¡çµ„
å¾å°ç£è­‰åˆ¸äº¤æ˜“æ‰€æŠ“å–å¤–è³‡ã€æŠ•ä¿¡ã€è‡ªç‡Ÿå•†è²·è³£è¶…è³‡æ–™
"""
import requests
import pandas as pd
from datetime import datetime, timedelta
import time

# è­‰äº¤æ‰€ API URL
TWSE_INSTITUTIONAL_URL = "https://www.twse.com.tw/fund/T86"
TPEX_INSTITUTIONAL_URL = "https://www.tpex.org.tw/web/stock/3insti/daily_trade/3itrade_hedge_result.php"

def get_institutional_data(date=None):
    """
    å–å¾—æŒ‡å®šæ—¥æœŸçš„ä¸‰å¤§æ³•äººè²·è³£è¶…è³‡æ–™
    
    Args:
        date: æ—¥æœŸ (YYYYMMDD æ ¼å¼)ï¼Œé è¨­ç‚ºä»Šå¤©
    
    Returns:
        dict: {ticker: {foreign: int, trust: int, dealer: int, total: int}}
    """
    if date is None:
        date = datetime.now().strftime('%Y%m%d')
    
    result = {}
    
    # æŠ“å–ä¸Šå¸‚è‚¡ç¥¨ï¼ˆTWSEï¼‰
    try:
        twse_data = fetch_twse_institutional(date)
        result.update(twse_data)
    except Exception as e:
        print(f"æŠ“å–ä¸Šå¸‚ä¸‰å¤§æ³•äººå¤±æ•—: {e}")
    
    # æŠ“å–ä¸Šæ«ƒè‚¡ç¥¨ï¼ˆTPExï¼‰
    try:
        tpex_data = fetch_tpex_institutional(date)
        result.update(tpex_data)
    except Exception as e:
        print(f"æŠ“å–ä¸Šæ«ƒä¸‰å¤§æ³•äººå¤±æ•—: {e}")
    
    return result

def fetch_twse_institutional(date):
    """æŠ“å–ä¸Šå¸‚è‚¡ç¥¨ä¸‰å¤§æ³•äººè³‡æ–™"""
    url = f"{TWSE_INSTITUTIONAL_URL}?response=json&date={date}&selectType=ALLBUT0999"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    }
    
    response = requests.get(url, headers=headers, timeout=30)
    data = response.json()
    
    result = {}
    
    if 'data' in data:
        for row in data['data']:
            try:
                # æ¬„ä½å®šç¾© (è­‰äº¤æ‰€æœ€æ–°æ ¼å¼ - 19 æ¬„):
                # [0] è­‰åˆ¸ä»£è™Ÿ
                # [1] è­‰åˆ¸åç¨±
                # [2] å¤–é™¸è³‡è²·é€²è‚¡æ•¸(ä¸å«å¤–è³‡è‡ªç‡Ÿå•†)
                # [3] å¤–é™¸è³‡è³£å‡ºè‚¡æ•¸(ä¸å«å¤–è³‡è‡ªç‡Ÿå•†)
                # [4] å¤–é™¸è³‡è²·è³£è¶…è‚¡æ•¸(ä¸å«å¤–è³‡è‡ªç‡Ÿå•†)
                # [5] å¤–è³‡è‡ªç‡Ÿå•†è²·é€²è‚¡æ•¸
                # [6] å¤–è³‡è‡ªç‡Ÿå•†è³£å‡ºè‚¡æ•¸
                # [7] å¤–è³‡è‡ªç‡Ÿå•†è²·è³£è¶…è‚¡æ•¸
                # [8] æŠ•ä¿¡è²·é€²è‚¡æ•¸
                # [9] æŠ•ä¿¡è³£å‡ºè‚¡æ•¸
                # [10] æŠ•ä¿¡è²·è³£è¶…è‚¡æ•¸
                # [11] è‡ªç‡Ÿå•†è²·è³£è¶…è‚¡æ•¸
                # [12-17] è‡ªç‡Ÿå•†ç´°é …
                # [18] ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸
                
                ticker = row[0].strip()
                
                # ç§»é™¤é€—è™Ÿä¸¦è½‰æ›ç‚ºæ•´æ•¸
                def parse_int(val):
                    return int(str(val).replace(',', '').replace(' ', ''))
                
                # å¤–è³‡ = å¤–é™¸è³‡ + å¤–è³‡è‡ªç‡Ÿå•†
                foreign = parse_int(row[4]) + parse_int(row[7])
                
                result[ticker + '.TW'] = {
                    'foreign': foreign,                 # å¤–è³‡è²·è³£è¶…ï¼ˆå«è‡ªç‡Ÿå•†ï¼‰
                    'trust': parse_int(row[10]),        # æŠ•ä¿¡è²·è³£è¶…
                    'dealer': parse_int(row[11]),       # è‡ªç‡Ÿå•†è²·è³£è¶…
                    'total': parse_int(row[18])         # ä¸‰å¤§æ³•äººåˆè¨ˆ
                }
            except:
                continue
    
    return result

def fetch_tpex_institutional(date):
    """æŠ“å–ä¸Šæ«ƒè‚¡ç¥¨ä¸‰å¤§æ³•äººè³‡æ–™"""
    # è½‰æ›æ—¥æœŸæ ¼å¼ YYYYMMDD -> YYY/MM/DD (æ°‘åœ‹å¹´)
    year = int(date[:4]) - 1911
    month = date[4:6]
    day = date[6:8]
    roc_date = f"{year}/{month}/{day}"
    
    url = f"{TPEX_INSTITUTIONAL_URL}?l=zh-tw&d={roc_date}&se=EW&t=D"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    }
    
    response = requests.get(url, headers=headers, timeout=30)
    data = response.json()
    
    result = {}
    
    if 'aaData' in data:
        for row in data['aaData']:
            try:
                ticker = row[0].strip()
                
                def parse_int(val):
                    return int(float(str(val).replace(',', '').replace(' ', '') or 0))
                
                result[ticker + '.TWO'] = {
                    'foreign': parse_int(row[4]),      # å¤–è³‡è²·è³£è¶…
                    'trust': parse_int(row[7]),        # æŠ•ä¿¡è²·è³£è¶…
                    'dealer': parse_int(row[10]),      # è‡ªç‡Ÿå•†è²·è³£è¶…
                    'total': parse_int(row[11])        # ä¸‰å¤§æ³•äººåˆè¨ˆ
                }
            except:
                continue
    
    return result

def get_recent_institutional(days=5):
    """
    å–å¾—æœ€è¿‘ N å¤©çš„ä¸‰å¤§æ³•äººç´¯è¨ˆè²·è³£è¶…
    
    Args:
        days: å¤©æ•¸
    
    Returns:
        dict: {ticker: {foreign: int, trust: int, dealer: int}}
    """
    cumulative = {}
    current_date = datetime.now()
    
    for i in range(days + 10):  # å¤šå–å¹¾å¤©é¿å…é‡åˆ°å‡æ—¥
        date = (current_date - timedelta(days=i)).strftime('%Y%m%d')
        
        try:
            daily_data = get_institutional_data(date)
            
            if daily_data:
                for ticker, values in daily_data.items():
                    if ticker not in cumulative:
                        cumulative[ticker] = {'foreign': 0, 'trust': 0, 'dealer': 0, 'days': 0}
                    
                    cumulative[ticker]['foreign'] += values['foreign']
                    cumulative[ticker]['trust'] += values['trust']
                    cumulative[ticker]['dealer'] += values['dealer']
                    cumulative[ticker]['days'] += 1
                
                # æª¢æŸ¥æ˜¯å¦å·²æ”¶é›†è¶³å¤ å¤©æ•¸
                if any(v['days'] >= days for v in cumulative.values()):
                    break
            
            time.sleep(0.5)  # é¿å…è«‹æ±‚éå¿«
            
        except Exception as e:
            print(f"å–å¾— {date} è³‡æ–™å¤±æ•—: {e}")
            continue
    
    return cumulative


def download_institutional_history(start_date, end_date=None, save_dir=None):
    """
    æ‰¹æ¬¡ä¸‹è¼‰æ³•äººæ­·å²è³‡æ–™
    
    Args:
        start_date: èµ·å§‹æ—¥æœŸ (YYYYMMDD)
        end_date: çµæŸæ—¥æœŸ (YYYYMMDD)ï¼Œé è¨­ç‚ºä»Šå¤©
        save_dir: å„²å­˜ç›®éŒ„ï¼Œé è¨­ç‚º data/institutional/
    
    Returns:
        dict: {date: {ticker: {...}}}
    """
    import os
    import json
    from pathlib import Path
    from tqdm import tqdm
    
    if end_date is None:
        end_date = datetime.now().strftime('%Y%m%d')
    
    if save_dir is None:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        save_dir = os.path.join(base_dir, "data", "institutional")
    
    Path(save_dir).mkdir(parents=True, exist_ok=True)
    
    # ç”¢ç”Ÿæ—¥æœŸæ¸…å–®
    start = datetime.strptime(start_date, '%Y%m%d')
    end = datetime.strptime(end_date, '%Y%m%d')
    
    dates = []
    current = start
    while current <= end:
        # è·³éé€±æœ«
        if current.weekday() < 5:
            dates.append(current.strftime('%Y%m%d'))
        current += timedelta(days=1)
    
    print(f"ğŸ“Š ä¸‹è¼‰æ³•äººæ­·å²è³‡æ–™")
    print(f"ğŸ“… æ—¥æœŸç¯„åœ: {start_date} ~ {end_date}")
    print(f"ğŸ“ å„²å­˜ä½ç½®: {save_dir}")
    print(f"ğŸ“‹ é è¨ˆä¸‹è¼‰: {len(dates)} å¤©")
    print()
    
    success = 0
    skipped = 0
    failed = 0
    total = len(dates)
    current = 0
    
    for date in tqdm(dates, desc="ä¸‹è¼‰é€²åº¦"):
        file_path = os.path.join(save_dir, f"{date}.json")
        current += 1
        
        # å¦‚æœæª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³é
        if os.path.exists(file_path):
            skipped += 1
            continue
        
        try:
            data = get_institutional_data(date)
            
            if data:
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                success += 1
                print(f"ğŸ“Š æ³•äººé€²åº¦: {current}/{total} ({current*100//total}%) | {date} æˆåŠŸ", flush=True)
            else:
                failed += 1
            
            time.sleep(0.5)  # é¿å…è«‹æ±‚éå¿«
            
        except Exception as e:
            failed += 1
            continue
    
    print()
    print("=" * 50)
    print(f"âœ… æˆåŠŸä¸‹è¼‰: {success}")
    print(f"ğŸ“ å·²å­˜åœ¨è·³é: {skipped}")
    print(f"âŒ å¤±æ•—/ç„¡è³‡æ–™: {failed}")
    print("=" * 50)


    print("=" * 50)


def auto_update():
    """
    è‡ªå‹•æ›´æ–°æ³•äººè³‡æ–™
    - æª¢æŸ¥ data/institutional/ ä¸‹æœ€æ–°çš„æª”æ¡ˆ
    - å¦‚æœæ²’æœ‰è³‡æ–™ï¼Œå¾ 20240101 é–‹å§‹æŠ“å–
    - å¦‚æœæœ‰è³‡æ–™ï¼Œå¾æœ€æ–°æ—¥æœŸçš„**ä¸‹ä¸€å¤©**é–‹å§‹æŠ“å–
    - æŠ“å–åˆ°**ä»Šå¤©**
    """
    import os
    from glob import glob
    from datetime import datetime, timedelta
    
    base_dir = os.path.dirname(os.path.abspath(__file__))
    save_dir = os.path.join(base_dir, "data", "institutional")
    
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
        
    # æ‰¾ç¾æœ‰æª”æ¡ˆ
    files = glob(os.path.join(save_dir, "*.json"))
    
    start_date = "20240101"  # é è¨­èµ·å§‹æ—¥
    
    if files:
        # æ‰¾å‡ºæœ€æ–°æ—¥æœŸ
        dates = [os.path.splitext(os.path.basename(f))[0] for f in files]
        dates.sort()
        last_date = dates[-1]
        
        # å¾ä¸‹ä¸€å¤©é–‹å§‹
        last_dt = datetime.strptime(last_date, '%Y%m%d')
        start_date = (last_dt + timedelta(days=1)).strftime('%Y%m%d')
        
    end_date = datetime.now().strftime('%Y%m%d')
    
    # å¦‚æœèµ·å§‹æ—¥å·²ç¶“æ™šæ–¼çµæŸæ—¥ï¼Œä»£è¡¨ä¸ç”¨æ›´æ–°
    if start_date > end_date:
        print(f"âœ… æ³•äººè³‡æ–™å·²æ˜¯æœ€æ–° ({end_date})")
        return
        
    print(f"ğŸ”„ è‡ªå‹•æ›´æ–°æ³•äººè³‡æ–™: {start_date} -> {end_date}")
    download_institutional_history(start_date, end_date, save_dir)


if __name__ == '__main__':
    import sys
    
    if len(sys.argv) > 1:
        cmd = sys.argv[1]
        if cmd == 'auto':
            # è‡ªå‹•æ›´æ–°æ¨¡å¼
            auto_update()
        else:
            # æ‰‹å‹•æŒ‡å®šæ—¥æœŸæ¨¡å¼
            start = sys.argv[1]
            end = sys.argv[2] if len(sys.argv) > 2 else None
            download_institutional_history(start, end)
    else:
        # é è¨­æ¸¬è©¦
        print("æ¸¬è©¦æŠ“å–ä»Šæ—¥ä¸‰å¤§æ³•äººè³‡æ–™...")
        data = get_institutional_data()
        print(f"å…±æŠ“å– {len(data)} æ”¯è‚¡ç¥¨")
        
        # é¡¯ç¤ºå‰ 5 ç­†
        for i, (ticker, values) in enumerate(list(data.items())[:5]):
            print(f"{ticker}: å¤–è³‡ {values['foreign']:+,} æŠ•ä¿¡ {values['trust']:+,} è‡ªç‡Ÿ {values['dealer']:+,}")
        
        print()
        print("ğŸ’¡ ä¸‹è¼‰æ­·å²è³‡æ–™ç”¨æ³•:")
        print("   python institutional.py auto              (è‡ªå‹•æ›´æ–°)")
        print("   python institutional.py 20240101 20241224 (æ‰‹å‹•æŒ‡å®šç¯„åœ)")

